{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "(1107, 'files found')\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_BGJD_1_SC_ES-05728.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_BGJD_1_SC_ES-5726_9.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_KYLS_6_SC_ES-05674.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_LRJE_7_SC_ES-05142.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_RDCS_1_SC_ES-04696.ann file as .txt file is no essay//'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SVJJ_2_SC_ES-05617.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SWAF_1_SC_ES-04832.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SWAF_1_SC_ES-04834.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SWSP_1_SC_ES-04853.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SYMS_3_SC_ES-05900.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SYMS_4_SC_ES-05980.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TFHC_1_SC_ES-05937.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TRDJ_11_SC_ES-05721.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TRKM_1_SC_ES-05026.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TTKP_4-5_SC_ES-04924.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TWDG_11_SC_ES-05463.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TWJB_7_SC_ES-05897.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TWNB_2_SC_ES-04977.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_WSAL_2_SC_ES-05361.ann file as .txt file is no essay'\n",
      "1088 essays processed\n"
     ]
    }
   ],
   "source": [
    "from BrattEssay import load_bratt_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "folder = settings.data_directory + \"SkinCancer/EBA1415_Merged/\"\n",
    "#folder = settings.data_directory + \"CoralBleaching/BrattData/EBA1415_Merged/\"\n",
    "essays = load_bratt_essays(folder)\n",
    "\n",
    "wd_sent_freq = defaultdict(int)\n",
    "all_codes = set()\n",
    "#Stores all words for the spelling corrector\n",
    "words = []\n",
    "all_sentences = []\n",
    "sentencesForCode = defaultdict(list)\n",
    "for essay in essays:\n",
    "    for sentence in essay.tagged_sentences:\n",
    "        wdsInSent = set()\n",
    "        codes4sentence = set()\n",
    "        sent = []\n",
    "        for w, tags in sentence:\n",
    "            words.append(w)\n",
    "            all_codes.update(tags)\n",
    "            codes4sentence.update(tags)\n",
    "            if w not in wdsInSent:\n",
    "                wdsInSent.add(w)\n",
    "                wd_sent_freq[w] += 1\n",
    "            sent.append(w)\n",
    "        all_sentences.append(sent)\n",
    "        for code in codes4sentence:\n",
    "            sentencesForCode[code].append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Stats over the Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd_counts = []\n",
    "sent_counts = []\n",
    "concept_codes = []\n",
    "cr_concept_codes = []\n",
    "sent_multi_word_tags = {}\n",
    "sent_codes = []\n",
    "sent_cr_codes = []\n",
    "\n",
    "num_sents = 0\n",
    "un_wd_counts = []\n",
    "for e_ix, essay in enumerate(essays):\n",
    "    wds = 0\n",
    "    un_words = set()\n",
    "    for i, sentence in enumerate(essay.tagged_sentences):\n",
    "        num_sents += 1\n",
    "        sent_tags = set()\n",
    "        sent_cr_tags = set()\n",
    "        for w, tags in sentence:\n",
    "            un_words.add(w)\n",
    "            wds += 1\n",
    "            ccodes = [t for t in tags if t[0].isdigit()]\n",
    "            if ccodes:\n",
    "                sent_tags.update(ccodes)\n",
    "                concept_codes.append(ccodes)\n",
    "                if len(ccodes) > 1:\n",
    "                    sent_multi_word_tags[(e_ix, i)] = [(w,[tag for tag in t if tag[0].isdigit()]) for w,t in sentence]\n",
    "            cr_codes = [t for t in tags if t[0].isdigit() or t == \"Causer\" or t == \"Result\" or t == \"explicit\"]\n",
    "            if cr_codes:\n",
    "                cr_concept_codes.append(cr_codes)\n",
    "                sent_cr_tags.update(cr_codes)\n",
    "        if len(sent_tags) > 0:\n",
    "            sent_codes.append(sent_tags)\n",
    "            if len(sent_cr_tags) > 0:\n",
    "                sent_cr_codes.append(sent_cr_tags)\n",
    "                \n",
    "    un_wd_counts.append(len(un_words))\n",
    "    sent_counts.append(len(essay.tagged_sentences))\n",
    "    wd_counts.append(wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((440, 9),\n",
       " [('Sunburn', ['5']),\n",
       "  ('happens', []),\n",
       "  ('when', []),\n",
       "  ('the', []),\n",
       "  ('body', []),\n",
       "  ('directs', []),\n",
       "  ('blood', []),\n",
       "  ('to', []),\n",
       "  ('try', []),\n",
       "  ('to', []),\n",
       "  ('repair', ['6']),\n",
       "  ('or', ['6']),\n",
       "  ('remove', ['6']),\n",
       "  ('cells', ['6', '4']),\n",
       "  ('damaged', ['6', '4']),\n",
       "  ('by', []),\n",
       "  ('the', []),\n",
       "  ('sun', ['2']),\n",
       "  ('.', [])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(sent_multi_word_tags), num_sents\n",
    "sent_multi_word_tags.items()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6671, 4555)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_codes), len([tags for tags in sent_codes if len(tags) > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay Length Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.267463235 157.0 4 479 82.449645775\n",
      "9.80698529412 9.0 1 36 5.02616928448\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print np.mean(wd_counts), np.median(wd_counts), np.min(wd_counts), np.max(wd_counts), np.std(wd_counts)\n",
    "print np.mean(sent_counts), np.median(sent_counts), np.min(sent_counts), np.max(sent_counts), np.std(sent_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 215, 90.163602941176464, 88.0, 36.152364440875424)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(un_wd_counts), np.max(un_wd_counts), np.mean(un_wd_counts), np.median(un_wd_counts), np.std(un_wd_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '11', '12', '2', '3', '4', '5', '50', '6'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IterableFP import flatten\n",
    "unique = set(flatten(concept_codes))\n",
    "unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Many Tagged Words Have Multiple Codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43024 180899 0.24\n",
      "2 4.64856824098e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['6', '4'], ['6', '4']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(concept_codes), sum(wd_counts), round(len(concept_codes) / float(sum(wd_counts)),2)\n",
    "multiple = [tags for tags in concept_codes if len(tags) > 1]\n",
    "print len(multiple), len(multiple) / float(len(concept_codes))\n",
    "multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1',\n",
       " '11',\n",
       " '12',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '50',\n",
       " '6',\n",
       " 'Causer',\n",
       " 'Result',\n",
       " 'explicit'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cr = set(flatten(cr_concept_codes))\n",
    "unique_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50260 180899 0.28\n",
      "34170 0.679864703542\n"
     ]
    }
   ],
   "source": [
    "print len(cr_concept_codes), sum(wd_counts), round(len(cr_concept_codes) / float(sum(wd_counts)),2)\n",
    "multiple = [tags for tags in cr_concept_codes if len(tags) > 1]\n",
    "print len(multiple), len(multiple) / float(len(cr_concept_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Proportion of Sentences With Codes Have Multiple Codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6828061759856093"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sents = float(num_sents)\n",
    "len(sent_codes) / num_sents\n",
    "num_multiple_codes = len([tags for tags in sent_codes if len(tags) > 1])\n",
    "num_multiple_codes / float(len(sent_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7507120371758357"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_cr_codes) / num_sents\n",
    "num_multiple_codes = len([tags for tags in sent_cr_codes if len(tags) > 1])\n",
    "num_multiple_codes / float(len(sent_cr_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probabilities of Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "priors = defaultdict(float)\n",
    "joints = defaultdict(float)\n",
    "\n",
    "for sent in sent_codes:\n",
    "    for a in sorted(sent):\n",
    "        priors[a] += 1\n",
    "        for b in sorted(sent):\n",
    "            if b >= a:\n",
    "                break\n",
    "            joints[(b,a)] +=1\n",
    "\n",
    "conditional = {}\n",
    "for a, cnt in priors.items():\n",
    "    for b in priors.keys():\n",
    "        if a == b:\n",
    "            continue\n",
    "        \"\"\" p(A/B) = p(B/A)p(A) / p(B) \"\"\"\n",
    "        \"\"\" p(A/B) = p(B/A)p(A) \"\"\"\n",
    "        if a < b:\n",
    "            joint = joints[(a,b)]\n",
    "        else:\n",
    "            joint = joints[(b,a)]\n",
    "        conditional[(a,b)] = joint / priors[b]\n",
    "    \n",
    "lifts = {}\n",
    "total = float(sum(joints.values()))\n",
    "totalPrior = float(sum(priors.values()))\n",
    "for (a,b),cnt in joints.items():\n",
    "    joint = cnt / total\n",
    "    pA = priors[a] / totalPrior\n",
    "    pB = priors[b] / totalPrior\n",
    "    lift = joint / (pA * pB)\n",
    "    if lift:\n",
    "        lifts[(a,b)] = lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& 1     & 2     &  1.83 \\\\\n",
      "& 2     & 3     &  1.19 \\\\\n",
      "& 3     & 4     &  1.54 \\\\\n",
      "& 4     & 5     &  1.39 \\\\\n",
      "& 5     & 6     &  1.69 \\\\\n",
      "& 6     & 50    &   1.1 \\\\\n",
      "& 6     & 12    &  -1.5 \\\\\n",
      "& 11    & 12    &  2.82 \\\\\n"
     ]
    }
   ],
   "source": [
    "def get_num(a):\n",
    "    s = \"\"\n",
    "    for c in a:\n",
    "        if c.isdigit():\n",
    "            s += c\n",
    "    return int(s)\n",
    "\n",
    "consec_pmi = {}\n",
    "for (a,b), lift in lifts.items():\n",
    "    ia = get_num(a)\n",
    "    ib = get_num(b)\n",
    "    diff = abs(ia-ib)\n",
    "    pmi = np.log(lift)\n",
    "    if \"Coral\" in folder:\n",
    "        if diff == 1 and b != \"6\" and b != \"5b\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"5\" and b ==\"5b\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"14\" and b ==\"5b\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"14\" and b ==\"6\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"50\" and b ==\"7\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "    elif \"Skin\" in folder:\n",
    "        if diff == 1:\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a == \"12\" and b == \"6\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a == \"50\" and b == \"6\":\n",
    "            consec_pmi[(a,b)] = pmi        \n",
    "            \n",
    "for k,v in sorted(consec_pmi.items(), key = lambda (k,v): (min(int(k[0]),int(k[1].replace(\"b\",\"\"))))):\n",
    "    a = k[0]\n",
    "    b = k[1]\n",
    "    if len(a) > len(b.replace(\"b\",\"\")):\n",
    "        a,b = b,a\n",
    "    print \"&\", str(a).ljust(5), \"&\", str(b).ljust(5), \"&\", str(round(v,2)).rjust(5), \"\\\\\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5111765747794741"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lifts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29579903430068333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(map(lambda l: np.log(l), lifts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('11', '12'), 16.729862357481394),\n",
       " (('11', '3'), 7.405751434489755),\n",
       " (('12', '3'), 7.211182655573351),\n",
       " (('1', '2'), 6.221040488119156),\n",
       " (('5', '6'), 5.424637638305385),\n",
       " (('3', '4'), 4.665913991679826),\n",
       " (('4', '5'), 4.016418788952101),\n",
       " (('4', '6'), 3.317247469708471),\n",
       " (('2', '3'), 3.274400630435474),\n",
       " (('5', '50'), 3.228817828809839),\n",
       " (('1', '50'), 3.0957572838200496),\n",
       " (('50', '6'), 2.9981403258405885),\n",
       " (('2', '50'), 2.6287234482050525),\n",
       " (('3', '50'), 1.939223843652011),\n",
       " (('2', '4'), 1.934500132777979),\n",
       " (('1', '3'), 1.8280169052807465),\n",
       " (('11', '50'), 1.4306591000477737),\n",
       " (('4', '50'), 1.3030148061014875),\n",
       " (('1', '11'), 1.245350887924594),\n",
       " (('3', '6'), 1.1303601304786342),\n",
       " (('2', '5'), 1.0909797087629334),\n",
       " (('11', '2'), 1.00827032383412),\n",
       " (('12', '4'), 0.9886534341480678),\n",
       " (('3', '5'), 0.9355091530934038),\n",
       " (('1', '5'), 0.7793797541411285),\n",
       " (('11', '5'), 0.7639145130541294),\n",
       " (('12', '2'), 0.6984659944821878),\n",
       " (('1', '4'), 0.6014908602065931),\n",
       " (('12', '50'), 0.58082932954614),\n",
       " (('11', '4'), 0.5432332548784073),\n",
       " (('2', '6'), 0.45035460773825436),\n",
       " (('12', '5'), 0.26736167196919786),\n",
       " (('1', '12'), 0.2397225074818528),\n",
       " (('12', '6'), 0.22307819340933022),\n",
       " (('11', '6'), 0.13007883874452408),\n",
       " (('1', '6'), 0.07201439888711465)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lifts.items(), key=lambda (tpl,p):-p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute Relative Class Frequencies At Word and Sentence Levels (Class Imbalances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd_cc_tally = defaultdict(int)\n",
    "sent_cc_tally = defaultdict(int)\n",
    "wd_cnt = 0\n",
    "sent_cnt = 0\n",
    "\n",
    "for e_ix, essay in enumerate(essays):\n",
    "\n",
    "    for i, sentence in enumerate(essay.tagged_sentences):\n",
    "        sent_cnt += 1\n",
    "        sent_tags = set()\n",
    "        sent_cr_tags = set()\n",
    "        \n",
    "        for w, tags in sentence:\n",
    "            wd_cnt += 1\n",
    "            # Concept Codes\n",
    "            ccodes = [t for t in tags if t[0].isdigit()]\n",
    "            if ccodes:\n",
    "                for cc in ccodes:\n",
    "                    wd_cc_tally[cc] += 1\n",
    "                    sent_tags.add(cc)\n",
    "            #Causal Codes\n",
    "            #This is wrong\n",
    "            #cr_codes = [t for t in tags if t[0].isdigit() or t == \"Causer\" or t == \"Result\" or t == \"explicit\"]\n",
    "            #if cr_codes:\n",
    "                 \n",
    "        if len(sent_tags) > 0:\n",
    "            for tag in sent_tags:\n",
    "                sent_cc_tally[tag] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180899, 10670)\n",
      "1   & 3.38 & 13.46 \\\\\n",
      "2   & 3.33 & 17.22 \\\\\n",
      "3   & 2.30 & 12.69 \\\\\n",
      "4   & 1.86 & 7.71 \\\\\n",
      "5   & 2.82 & 21.94 \\\\\n",
      "6   & 2.88 & 9.20 \\\\\n",
      "11  & 0.33 & 2.98 \\\\\n",
      "12  & 0.52 & 6.08 \\\\\n",
      "50  & 6.36 & 29.29 \\\\\n"
     ]
    }
   ],
   "source": [
    "print(wd_cnt, sent_cnt)\n",
    "#Code, Number of Words, Proportion\n",
    "for code, wd_tally in sorted(wd_cc_tally.items(), key = lambda tpl: int(tpl[0].replace(\"b\",\"\"))):\n",
    "    wd_pct = 100* (float(wd_tally) / wd_cnt)\n",
    "    sent_pct = 100*(float(sent_cc_tally[code]) / sent_cnt)\n",
    "    #print(code.ljust(2), str(tally).ljust(6), \"{0:.4f}\".format(float(tally)/wd_cnt))\n",
    "    # 1 & 0.332 & 1.27 & & 1  & 0.123 & 0.234 \\\\\n",
    "    print(\"{code} & {wd_pct:.2f} & {sent_pct:.2f} \\\\\\\\\".format(code=code.ljust(3),wd_pct=wd_pct, sent_pct=sent_pct))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Relative Frequencies of Each Causal Relation (Word and Sentence Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd_cr_tally = defaultdict(int)\n",
    "sent_cr_tally = defaultdict(int)\n",
    "wd_cr_cnt = 0\n",
    "sent_cr_cnt = 0\n",
    "\n",
    "for e_ix, essay in enumerate(essays):\n",
    "\n",
    "    for i, sentence in enumerate(essay.tagged_sentences):\n",
    "        sent_cr_cnt += 1\n",
    "        sent_tags = set()\n",
    "        sent_cr_tags = set()\n",
    "        \n",
    "        for w, tags in sentence:\n",
    "            wd_cr_cnt += 1\n",
    "            # Concept Codes\n",
    "            cr_codes = list((t for t in tags if ( \"->\" in t) and not \"factor\" in t and not \"Anaphor\" in t and not \"other\" in t and not \"rhetorical\" in t))\n",
    "            if cr_codes:\n",
    "                for cr in cr_codes:\n",
    "                    wd_cr_tally[cr] += 1\n",
    "                    sent_tags.add(cr)           \n",
    "        if len(sent_tags) > 0:\n",
    "            for tag in sent_tags:\n",
    "                sent_cr_tally[tag] +=1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cc_to_float(cc):\n",
    "    if \"b\" in cc:\n",
    "        cc = cc.replace(\"b\",\"\")\n",
    "        cc += \".1\"\n",
    "    return float(cc)\n",
    "\n",
    "def sort_key(tpl):\n",
    "    cr,cnt = tpl\n",
    "    cr = cr.replace(\"Causer:\",\"\")\n",
    "    cr = cr.replace(\"Result:\",\"\")\n",
    "    l,r = cr.split(\"->\")\n",
    "    l,r = cc_to_float(l), cc_to_float(r)\n",
    "    return (l,r)\n",
    "\n",
    "srtd_cnts = sorted(wd_cr_tally.items(), key = sort_key)\n",
    "\n",
    "prev = \"\"\n",
    "\n",
    "lines = []\n",
    "for cr, wd_tally in srtd_cnts:\n",
    "    l,r = cr.split(\"->\")\n",
    "    if l != prev:\n",
    "        #print(\"\\cmidrule{1-3}\")\n",
    "        prev = l\n",
    "    wd_pct = 100 * (float(wd_tally) / wd_cr_cnt)\n",
    "    sent_pct = 100 *(float(sent_cr_tally[cr]) / sent_cnt)\n",
    "    # Print Latex Output (Near End of chapter 2)\n",
    "    cr = cr.replace(\"->\",\"\\\\textrightarrow \")\n",
    "    cr = cr.replace(\"Causer:\",\"\").replace(\"Result:\",\"\")\n",
    "    lines.append(\"{cr} & {wd_pct:.2f} & {sent_pct:.2f}\".format(cr=cr.ljust(25),wd_pct=wd_pct, sent_pct=sent_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\\textrightarrow 2        & 3.77 & 5.78 & & 5\\textrightarrow 4        & 0.29 & 0.63 \\\\\n",
      "1\\textrightarrow 3        & 0.57 & 0.73 & & 5\\textrightarrow 5        & 0.04 & 0.07 \\\\\n",
      "1\\textrightarrow 4        & 0.03 & 0.04 & & 5\\textrightarrow 6        & 3.19 & 5.03 \\\\\n",
      "1\\textrightarrow 5        & 0.19 & 0.25 & & 5\\textrightarrow 12       & 0.01 & 0.01 \\\\\n",
      "1\\textrightarrow 50       & 3.37 & 5.11 & & 5\\textrightarrow 50       & 5.31 & 8.76 \\\\\n",
      "2\\textrightarrow 1        & 0.01 & 0.02 & & 6\\textrightarrow 3        & 0.00 & 0.01 \\\\\n",
      "2\\textrightarrow 2        & 0.01 & 0.02 & & 6\\textrightarrow 4        & 0.01 & 0.02 \\\\\n",
      "2\\textrightarrow 3        & 1.36 & 2.61 & & 6\\textrightarrow 5        & 0.05 & 0.07 \\\\\n",
      "2\\textrightarrow 4        & 0.44 & 0.74 & & 6\\textrightarrow 50       & 2.24 & 4.01 \\\\\n",
      "2\\textrightarrow 5        & 0.61 & 1.03 & & 11\\textrightarrow 3       & 0.09 & 0.12 \\\\\n",
      "2\\textrightarrow 6        & 0.03 & 0.03 & & 11\\textrightarrow 4       & 0.01 & 0.01 \\\\\n",
      "2\\textrightarrow 11       & 0.00 & 0.01 & & 11\\textrightarrow 5       & 0.03 & 0.05 \\\\\n",
      "2\\textrightarrow 50       & 3.98 & 6.12 & & 11\\textrightarrow 12      & 0.69 & 1.63 \\\\\n",
      "3\\textrightarrow 2        & 0.01 & 0.02 & & 11\\textrightarrow 50      & 0.42 & 0.59 \\\\\n",
      "3\\textrightarrow 4        & 1.39 & 2.20 & & 12\\textrightarrow 2       & 0.07 & 0.17 \\\\\n",
      "3\\textrightarrow 5        & 0.21 & 0.39 & & 12\\textrightarrow 3       & 0.95 & 2.72 \\\\\n",
      "3\\textrightarrow 6        & 0.21 & 0.27 & & 12\\textrightarrow 4       & 0.01 & 0.02 \\\\\n",
      "3\\textrightarrow 11       & 0.01 & 0.01 & & 12\\textrightarrow 5       & 0.02 & 0.05 \\\\\n",
      "3\\textrightarrow 50       & 2.23 & 3.66 & & 12\\textrightarrow 12      & 0.00 & 0.01 \\\\\n",
      "4\\textrightarrow 4        & 0.01 & 0.02 & & 12\\textrightarrow 50      & 0.10 & 0.18 \\\\\n",
      "4\\textrightarrow 5        & 1.27 & 2.33 & & 50\\textrightarrow 2       & 0.03 & 0.04 \\\\\n",
      "4\\textrightarrow 6        & 0.34 & 0.52 & & 50\\textrightarrow 3       & 0.01 & 0.02 \\\\\n",
      "4\\textrightarrow 11       & 0.00 & 0.01 & & 50\\textrightarrow 4       & 0.01 & 0.01 \\\\\n",
      "4\\textrightarrow 12       & 0.00 & 0.01 & & 50\\textrightarrow 5       & 0.01 & 0.02 \\\\\n",
      "4\\textrightarrow 50       & 0.60 & 0.94 & &  \\\\\n"
     ]
    }
   ],
   "source": [
    "half = int(len(lines)+1)//2\n",
    "#if len(lines) % 2 != 0:\n",
    "#    half += 1\n",
    "\n",
    "for i in range(0,half):\n",
    "    left = lines[i]\n",
    "    right = \"\"\n",
    "    if i + half  < (len(lines)):\n",
    "        right = lines[i+half]\n",
    "    print(left + \" & & \" + right + \" \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:phd]",
   "language": "python",
   "name": "conda-env-phd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
