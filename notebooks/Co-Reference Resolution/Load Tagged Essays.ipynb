{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dill\n",
    "\n",
    "#from gensim.models import Word2Vec\n",
    "from window_based_tagger_config import get_config\n",
    "from Rpfa import micro_rpfa\n",
    "\n",
    "import logging\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from BrattEssay import load_bratt_essays\n",
    "from load_data import load_process_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "\n",
    "CV_FOLDS = 5\n",
    "DEV_SPLIT = 0.1\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "training_pickled = settings.data_directory + \"CoralBleaching/Thesis_Dataset/training.pl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 files found\n",
      "902 essays processed\n"
     ]
    }
   ],
   "source": [
    "config = get_config(training_folder)\n",
    "# override this so we don't replace INFREQUENT words\n",
    "config[\"min_df\"] = 0\n",
    "tagged_essays2 = load_process_essays(**config)\n",
    "#config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_essays2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/Training'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coref_folder = root_folder + \"CoReference/Training_Old\"\n",
    "coref_folder = root_folder + \"CoReference/Training\"\n",
    "coref_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from FindFiles import find_files\n",
    "coref_files = find_files(coref_folder, \".*\\.tagged\")\n",
    "len(coref_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "DELIM = \"->\"\n",
    "DELIM_TAG = \"|||\"\n",
    "\n",
    "essay2tagged = {}\n",
    "for fname in coref_files:\n",
    "    with open(fname) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    tagged_lines = []    \n",
    "    for line in lines:\n",
    "        tagged_words = []\n",
    "        line = line.strip()\n",
    "        wds = []\n",
    "        for t_token in line.split(\" \"):\n",
    "            ##print(t_token)\n",
    "            splt = t_token.split(DELIM)\n",
    "            word, tags = t_token.split(DELIM)\n",
    "            wds.append(word)\n",
    "            tag_dict = {}\n",
    "            for tag in tags.split(DELIM_TAG):\n",
    "                if not tag:\n",
    "                    continue\n",
    "                splt = tag.split(\":\")\n",
    "                if len(splt) == 2:\n",
    "                    key,val = splt\n",
    "                    tag_dict[key] = val\n",
    "                else:\n",
    "                    raise Exception(\"Error\")\n",
    "            tagged_words.append((word, tag_dict))\n",
    "        tagged_lines.append(tagged_words)\n",
    "    essay2tagged[fname.split(\"/\")[-1].split(\".\")[0]] = tagged_lines\n",
    "print(len(essay2tagged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5125, 5125, 5125)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions = []\n",
    "mention_lens = []\n",
    "\n",
    "current_ph_len = 0\n",
    "current_mention = \"\"\n",
    "prev_phrase = \"\"\n",
    "\n",
    "mention2replace = []\n",
    "\n",
    "def change_in_phrase():\n",
    "    global mentions, mention_lens, current_ph_len, current_mention, prev_phrase, mention2replace \n",
    "    if current_ph_len > 0:\n",
    "        mention_lens.append(current_ph_len)\n",
    "        mentions.append(current_mention.strip())\n",
    "        mention2replace.append((current_mention.strip(), prev_phrase))\n",
    "    current_mention = \"\"\n",
    "    current_ph_len = 0\n",
    "    prev_phrase = \"\"\n",
    "\n",
    "for ename, tagged_lines in essay2tagged.items():\n",
    "    #print(ename)\n",
    "    for line in tagged_lines:\n",
    "        current_ph_len = 0\n",
    "        current_mention = \"\"\n",
    "        prev_phrase = \"\"\n",
    "        for wd, tag_dict in line:\n",
    "            if \"COREF_PHRASE\" in tag_dict:\n",
    "                current_phrase = tag_dict[\"COREF_PHRASE\"]\n",
    "                if prev_phrase != current_phrase:\n",
    "                    change_in_phrase()\n",
    "                current_ph_len+=1\n",
    "                current_mention += \" \" + wd\n",
    "                prev_phrase = tag_dict[\"COREF_PHRASE\"]\n",
    "            else:\n",
    "                change_in_phrase()\n",
    "        change_in_phrase()\n",
    "len(mention_lens), len(mentions), len(mention2replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5473170731707317, 20, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(mention_lens), np.max(mention_lens), np.min(mention_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5473170731707317, 20, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = list(map(lambda s: len(s.strip().split(\" \")), mentions))\n",
    "np.mean(lens), np.max(lens), np.min(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['producers -lrb- things that create food using sunlight like coral reef -rrb-',\n",
       " 'the salty water',\n",
       " 'the pacific ocean',\n",
       " 'corals living in the oceans',\n",
       " 'the atlantic ocean',\n",
       " 'the amount of carbon dioxide',\n",
       " 'the amount of co2',\n",
       " 'the coral reef',\n",
       " 'the amount of fresh water',\n",
       " 'the zooxanthallae algae']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in mentions if len(m.strip().split(\" \")) >= 3][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the winds',\n",
       "  'the_trade_winds_that_go_through_upwelling_which_can_increase_the_temperature_from_3of_to_5of_and_in_some_places_they_increase_over_10of'),\n",
       " ('the trade winds',\n",
       "  'the_trade_winds_that_go_through_upwelling_which_can_increase_the_temperature_from_3of_to_5of_and_in_some_places_they_increase_over_10of'),\n",
       " ('the photosynthesis',\n",
       "  'the_photosynthesis_the_polyps_go_through_to_recieve_energy_to_give_to_the_coral_which_they_need_00_%_to_00_%_of'),\n",
       " ('the ways',\n",
       "  'many_ways_to_explain_the_rates_in_coral_bleaching_like_trade_winds_,_a_balanced_environment_,_and_physical_damage'),\n",
       " ('it',\n",
       "  'the_change_in_carbon_dioxide_which_is_a_cause_of_different_temperatures_and_extreme_storms_coral_how_salty_the_water'),\n",
       " ('it',\n",
       "  'the_change_in_carbon_dioxide_which_is_a_cause_of_different_temperatures_and_extreme_storms_coral_how_salty_the_water'),\n",
       " ('the algae',\n",
       "  'the_algae_,_called_zooxanthellae_,_that_lives_in_the_tissues_of_the_coral_need_sunlight_for_photosynthesis'),\n",
       " ('the algae',\n",
       "  'the_algae_,_called_zooxanthellae_,_that_lives_in_the_tissues_of_the_coral_need_sunlight_for_photosynthesis'),\n",
       " ('this algae',\n",
       "  'the_algae_,_called_zooxanthellae_,_that_lives_in_the_tissues_of_the_coral_need_sunlight_for_photosynthesis'),\n",
       " ('the coral',\n",
       "  'the_coral_which_is_in_the_pacific_ocean_and_also_because_how_the_people_affect_the_coral_bleaching'),\n",
       " ('the coral',\n",
       "  'the_coral_which_is_in_the_pacific_ocean_and_also_because_how_the_people_affect_the_coral_bleaching'),\n",
       " ('the coral',\n",
       "  'the_coral_which_is_in_the_pacific_ocean_and_also_because_how_the_people_affect_the_coral_bleaching'),\n",
       " ('it',\n",
       "  'this_mostly_in_the_pacific_ocean_which_is_good_for_corals_reefs_to_live_in_shifting_the_wind'),\n",
       " ('the salinity',\n",
       "  'water_salinity_-lrb-_how_salty_the_water_is_-rrb-_salt_levels_can_decrease_during_storms_with_excessive_rainfall'),\n",
       " ('the environment',\n",
       "  'a_nutrient_-_rich_environment_for_the_algae_,_the_zooxanthellae_pass_food_to_the_coral_with_color'),\n",
       " ('itself',\n",
       "  'the_coral_itself_,_coral_is_not_what_people_think_it_is_,_it_an_animal_like_polyps'),\n",
       " ('it',\n",
       "  'the_coral_itself_,_coral_is_not_what_people_think_it_is_,_it_an_animal_like_polyps'),\n",
       " ('this event',\n",
       "  'a_bleaching_event_in_0000_,_which_is_considered_to_be_one_of_the_worst_ever_observed'),\n",
       " ('itself',\n",
       "  'a_massive_effect_not_only_on_the_coral_itself_,_but_on_the_world_many_coral_reefs'),\n",
       " ('the energy it needs to survive',\n",
       "  'the_photosynthesis_zooxanthellae_use_energy_from_sunlight_to_combine_carbon_dioxide_in_the_ocean_with_water'),\n",
       " ('the water temperature',\n",
       "  'the_water_temperature_,_upwelling_,_movement_of_water_,_the_amount_and_severity_of_storms'),\n",
       " ('the algae',\n",
       "  'the_algae_that_has_not_been_ejected_most_likely_dies_because_it_can_not_preform_photosynthesis'),\n",
       " ('it',\n",
       "  'the_algae_that_has_not_been_ejected_most_likely_dies_because_it_can_not_preform_photosynthesis'),\n",
       " ('it',\n",
       "  'the_algae_that_has_not_been_ejected_most_likely_dies_because_it_can_not_preform_photosynthesis'),\n",
       " ('it',\n",
       "  'the_algae_that_has_not_been_ejected_most_likely_dies_because_it_can_not_preform_photosynthesis'),\n",
       " ('that',\n",
       "  \"some_things_that_can_happen_to_coral_that_may_lead_to_''_coral_bleaching_''\"),\n",
       " ('this phenomenon',\n",
       "  'a_phenomenon_with_coral_that_causes_it_to_loose_it_color_and_turn_plain_white'),\n",
       " ('the water temperatures',\n",
       "  'the_highest_water_temperatures_recorded_,_which_was_a_result_of_weaker_trade_winds'),\n",
       " ('these changes in the environment',\n",
       "  'some_changes_in_the_environment_that_can_threaten_the_process_between_coral_and_algae'),\n",
       " ('the event',\n",
       "  'a_massive_coral_bleaching_event_that_was_considered_one_of_the_worst_ones_observed'),\n",
       " ('this event',\n",
       "  'a_massive_coral_bleaching_event_in_0000_considered_one_of_the_worst_ever_observed'),\n",
       " ('the coral',\n",
       "  'the_coral_like_blast_fishing_,_anchors_or_people_walking_dropping_on_the_corals'),\n",
       " ('it',\n",
       "  'the_coral_like_blast_fishing_,_anchors_or_people_walking_dropping_on_the_corals'),\n",
       " ('it',\n",
       "  'the_coral_like_blast_fishing_,_anchors_or_people_walking_dropping_on_the_corals'),\n",
       " ('the water',\n",
       "  'the_water_their_in_to_be_between_seventy_and_eighty_-_five_degrees_farinheight')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(mention2replace, key = lambda s: -len(s[1].split(\"_\")))[:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m,h in mention2replace:\n",
    "#     if len(m.split(\" \")) > len(h.split(\"_\")):\n",
    "#         print(m)\n",
    "#         print(h)\n",
    "#         print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 902)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay2parsed = {}\n",
    "for e in tagged_essays2:\n",
    "    essay2parsed[e.name.split(\".\")[0]] = e\n",
    "len(essay2parsed), len(essay2tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set(essay2parsed.keys())\n",
    "b = set(essay2tagged.keys())\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBA1415_AEKD_5_CB_ES-05579 15 12 233 234 True\n",
      "EBA1415_BGJD_2_CB_ES-05747 2 1 15 13 False\n",
      "EBA1415_BLRW_3_CB_ES-05168 11 10 156 154 False\n",
      "EBA1415_BLRW_3_CB_ES-05174 16 16 262 263 True\n",
      "EBA1415_BLRW_3_CB_ES-05180 12 12 171 172 True\n",
      "EBA1415_ERAP_7_CB_ES-05464 15 15 225 226 True\n",
      "EBA1415_ERSK_7_CB_ES-05793 10 10 143 141 False\n",
      "EBA1415_ERSK_7_CB_ES-06271 4 5 67 63 False\n",
      "EBA1415_HNJD_4_CB_ES-05810 29 29 386 387 True\n",
      "EBA1415_KNKC_3_CB_ES-05589 5 5 97 98 True\n",
      "EBA1415_KNKC_3_CB_ES-05590 13 13 270 268 False\n",
      "EBA1415_KNKC_3_CB_ES-05601 4 4 180 178 False\n",
      "EBA1415_KNKC_3_CB_ES-05606 6 13 173 171 False\n",
      "EBA1415_KYLS_5_CB_ES-05648 15 14 300 298 False\n",
      "EBA1415_KYLS_5_CB_ES-05664 10 10 200 201 True\n",
      "EBA1415_KYLS_6_CB_ES-05682 6 5 83 81 False\n",
      "EBA1415_KYLS_6_CB_ES-05684 12 12 254 255 True\n",
      "EBA1415_KYNS_4_CB_ES-05393 14 15 280 281 True\n",
      "EBA1415_KYNS_4_CB_ES-05400 10 10 248 250 True\n",
      "EBA1415_KYNS_4_CB_ES-05403 11 12 206 204 False\n",
      "EBA1415_LRBL_4_CB_ES-05164 8 6 104 105 True\n",
      "EBA1415_LRJE_7_CB_ES-05138 19 19 216 217 True\n",
      "EBA1415_LRJE_7_CB_ES-05143 9 9 142 140 False\n",
      "EBA1415_LZBA_3_CB_ES-05505 10 10 283 284 True\n",
      "EBA1415_LZBA_4_CB_ES-05530 16 16 286 287 True\n",
      "EBA1415_RDJK_5_CB_ES-04725 14 14 240 241 True\n",
      "EBA1415_RHSG_1_CB_ES-05072 9 9 166 167 True\n",
      "EBA1415_RHSGa_3_CB_ES-05089 8 8 152 153 True\n",
      "EBA1415_SDLC_2_CB_ES-04740 16 16 237 238 True\n",
      "EBA1415_SDLC_2_CB_ES-04745 10 10 199 200 True\n",
      "EBA1415_SDMK_4_CB_ES-04764 12 12 268 269 True\n",
      "EBA1415_SDMK_6_CB_ES-04777 15 15 256 257 True\n",
      "EBA1415_SEAL_34_CB_ES-04798 13 15 230 228 False\n",
      "EBA1415_SEAL_34_CB_ES-05695 13 13 203 204 True\n",
      "EBA1415_SEAL_78_CB-04800 16 16 226 227 True\n",
      "EBA1415_SEKL_1_CB-04814 18 18 267 268 True\n",
      "EBA1415_SEKL_23_CB_ES-04827 10 10 115 116 True\n",
      "EBA1415_SERS_1314_CB-05100 11 11 282 280 False\n",
      "EBA1415_SERS_1314_CB-05930 10 10 161 162 True\n",
      "EBA1415_SERS_1314_CB_ES-05107 15 15 167 168 True\n",
      "EBA1415_SERS_1314_CB_ES-05108 11 11 159 160 True\n",
      "EBA1415_SERS_1516_CB-05117 21 21 303 304 True\n",
      "EBA1415_SVJJ_4_CB_ES-05625 18 18 348 350 True\n",
      "EBA1415_SWAF_6_CB_ES-04840 7 6 102 100 False\n",
      "EBA1415_SWCT_6_CB-04865 14 14 175 176 True\n",
      "EBA1415_SWCT_6_CB-04870 25 24 336 332 False\n",
      "EBA1415_SWCT_7_CB_ES-04897 18 18 297 298 True\n",
      "EBA1415_SWSP_4_CB_ES-04856 6 6 96 97 True\n",
      "EBA1415_SYMS_3_CB_ES-05563 10 10 171 172 True\n",
      "EBA1415_SYMS_4_CB_ES-05982 8 8 219 217 False\n",
      "EBA1415_TFBM_2_CB_ES-05448 15 15 282 279 False\n",
      "EBA1415_TFBM_2_CB_ES-05554 8 8 147 148 True\n",
      "EBA1415_TFBM_2_CB_ES-05557 17 17 267 268 True\n",
      "EBA1415_TFHC_1_CB_ES-05947 19 19 341 342 True\n",
      "EBA1415_TFHC_1_CB_ES-05967 7 6 190 180 False\n",
      "EBA1415_TFMV_3_CB_ES-05846 16 15 298 296 False\n",
      "EBA1415_TRJB_2_CB_ES-06119 7 6 81 79 False\n",
      "EBA1415_TTCM_910_CB_ES-06150 10 10 166 162 False\n",
      "EBA1415_TTFW_2_CB_ES-04910 3 3 143 141 False\n",
      "EBA1415_TTKP_45_CB_ES-04921 4 3 56 54 False\n",
      "EBA1415_TTKP_45_CB_ES-6159 6 6 111 112 True\n",
      "EBA1415_TWJB_7_CB_ES-05058 19 19 332 333 True\n",
      "EBA1415_TWNB_3_CB_ES-04980 6 6 167 168 True\n",
      "EBA1415_WSAL_1_CB_ES-05350 9 8 162 158 False\n",
      "EBA1415_WSAL_1_CB_ES-05354 5 5 124 125 True\n",
      "EBA1415_WSKT_1_CB_ES-05315 26 26 349 350 True\n",
      "EBA1415_WSKT_6_CB_ES-05340 9 9 175 176 True\n",
      "EBA1415post_TWMD_67_CB_ES-06192 8 8 151 152 True\n",
      "EBA1415post_TWNB_3_CB_ES-04981 23 23 292 278 False\n",
      "EBA1415post_TWNB_3_CB_ES-04984 22 22 372 373 True\n",
      "EBA1415post_TWPK_3_CB_ES-06195 11 11 197 198 True\n",
      "EBA1415post_WSAL_2_CB_ES-05365 12 12 239 240 True\n",
      "EBA1415post_WSKT_6_CB_ES-05347 10 10 174 175 True\n"
     ]
    }
   ],
   "source": [
    "diffs = 0\n",
    "for ename, tagged_essay in essay2tagged.items():\n",
    "    assert ename in essay2parsed\n",
    "    essay = essay2parsed[ename]\n",
    "    \n",
    "    wds1 = 0\n",
    "    for sent in essay.sentences:\n",
    "        for wd,tags in sent:\n",
    "            wds1 += 1\n",
    "\n",
    "    wds2 = 0\n",
    "    for sent in tagged_essay:\n",
    "        for wd in sent:\n",
    "            wds2 += 1\n",
    "    if wds1 != wds2:\n",
    "        diffs+=1\n",
    "        print(ename,  len(essay.sentences), len(tagged_essay), wds1, wds2, wds2>=wds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 902)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs, len(essay2tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_essay), len(essay.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('animals', 'animals'),\n",
       " ('particles', 'particles'),\n",
       " ('are', 'are'),\n",
       " ('gonna', 'gon'),\n",
       " ('begin', 'na'),\n",
       " ('to', 'begin'),\n",
       " ('die', 'to'),\n",
       " ('out', 'die'),\n",
       " (',', 'out'),\n",
       " ('because', ','),\n",
       " ('they', 'because'),\n",
       " ('cant', 'they'),\n",
       " ('gain', 'cant')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = \"EBA1415_WSAL_1_CB_ES-05354\"\n",
    "essay = essay2parsed[key]\n",
    "tessay = essay2tagged[key]\n",
    "\n",
    "wds1, wds2 = [],[]\n",
    "for sent in essay.sentences:\n",
    "    for wd,tags in sent:\n",
    "        wds1.append(wd)\n",
    "        \n",
    "for sent in tessay:\n",
    "    for wd,tags in sent:\n",
    "        wds2.append(wd)\n",
    "ix = 0\n",
    "for a,b in zip(wds1,wds2):\n",
    "    if a != b:\n",
    "        break\n",
    "    ix += 1\n",
    "list(zip(wds1[ix-3:ix+10],wds2[ix-3:ix+10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the the\n",
      "differences differences\n",
      "in in\n",
      "the the\n",
      "rates rates\n",
      "of of\n",
      "coral coral\n",
      "bleaching bleaching\n",
      "is is\n",
      "that that\n",
      "first first\n",
      "it it\n",
      "started started\n",
      "out out\n",
      "not not\n",
      "so so\n",
      "major major\n",
      "in in\n",
      "0000 0000\n",
      ", ,\n",
      "but but\n",
      "than than\n",
      "it it\n",
      "started started\n",
      "increasing increasing\n",
      ". .\n",
      "the the\n",
      "highest highest\n",
      "rate rate\n",
      "was was\n",
      "in in\n",
      "0000 0000\n",
      "it it\n",
      "reached reached\n",
      "up up\n",
      "to to\n",
      "more more\n",
      "than than\n",
      "00 00\n",
      "countries countries\n",
      "making making\n",
      "a a\n",
      "report report\n",
      "of of\n",
      "coral coral\n",
      "bleaching bleaching\n",
      ". .\n",
      "so so\n",
      "on on\n",
      "it it\n",
      "started started\n",
      "decreasing decreasing\n",
      "from from\n",
      "there there\n",
      ". .\n",
      "than than\n",
      "again again\n",
      "who who\n",
      "knows knows\n",
      "how how\n",
      "bad bad\n",
      "it it\n",
      "is is\n",
      "now now\n",
      "0000 0000\n",
      ". .\n",
      "the the\n",
      "coral coral\n",
      "bleaching bleaching\n",
      "reports reports\n",
      "only only\n",
      "went went\n",
      "from from\n",
      "0000 0000\n",
      "- -\n",
      "0000 0000\n",
      ". .\n",
      "\" ''\n",
      "**********miss match**********\n",
      "Found: also also 78 78\n"
     ]
    }
   ],
   "source": [
    "key = \"EBA1415_BLRW_3_CB_ES-05168\"\n",
    "essay = essay2parsed[key]\n",
    "tessay = essay2tagged[key]\n",
    "\n",
    "wds1, wds2 = [],[]\n",
    "for sent in essay.sentences:\n",
    "    for wd,tags in sent:\n",
    "        wds1.append(wd)\n",
    "        \n",
    "for sent in tessay:\n",
    "    for wd,tags in sent:\n",
    "        wds2.append(wd)\n",
    "        \n",
    "ix_a, ix_b = 0,0\n",
    "scan_length = 5\n",
    "print_wds = True\n",
    "while ix_a < len(wds1) and ix_b < len(wds2):\n",
    "    a = wds1[ix_a]\n",
    "    b = wds2[ix_b]\n",
    "    if print_wds:\n",
    "        print(a,b)\n",
    "    if a != b:\n",
    "        \n",
    "        print_wds = True\n",
    "        print(\"*\" * 10 + \"miss match\" + \"*\" * 10)        \n",
    "        next_a = wds1[ix_a+1]\n",
    "        next_b = wds2[ix_b+1]\n",
    "        # look ahead in wds2 for item that matches next a\n",
    "        found_match = False\n",
    "        for offseta, aa in enumerate(wds1[ix_a:ix_a+1+scan_length]):\n",
    "            for offsetb, bb in enumerate(wds2[ix_b:ix_b+1+scan_length]):\n",
    "                if aa == bb:\n",
    "                    ix_a = ix_a + offseta\n",
    "                    ix_b = ix_b + offsetb\n",
    "                    found_match = True\n",
    "                    print(\"Found:\", aa,bb,ix_a,ix_b)\n",
    "                    break\n",
    "            if found_match:\n",
    "                break\n",
    "                \n",
    "        if found_match:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Failed: \", a, b)\n",
    "    else:            \n",
    "        ix_a += 1\n",
    "        ix_b += 1\n",
    "    \n",
    "###list(zip(wds1[ix-3:ix+10],wds2[ix-3:ix+10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs = 0\n",
    "failed_cnt = 0\n",
    "for ename, tagged_essay in essay2tagged.items():\n",
    "    assert ename in essay2parsed\n",
    "    essay = essay2parsed[ename]\n",
    "         \n",
    "    wds1 = []\n",
    "    for sent in essay.sentences:\n",
    "        for wd,tags in sent:\n",
    "            wds1.append(wd)\n",
    "\n",
    "    wds2 = []\n",
    "    for sent in tagged_essay:\n",
    "        for wd,tag_dict in sent:\n",
    "            wds2.append(wd)\n",
    "            \n",
    "    ix_a, ix_b = 0,0\n",
    "\n",
    "    scan_length = 5\n",
    "    while ix_a < (len(wds1)-1) and ix_b < (len(wds2)-1):\n",
    "        a = wds1[ix_a]\n",
    "        b = wds2[ix_b]\n",
    "#         print(a,b)\n",
    "        if a != b:\n",
    "#             print(\"*\" * 10 + \"miss match\" + \"*\" * 10)            \n",
    "            # look ahead in wds2 for item that matches next a\n",
    "            found_match = False\n",
    "            for offseta, aa in enumerate(wds1[ix_a: ix_a+1+scan_length]):\n",
    "                for offsetb, bb in enumerate(wds2[ix_b:ix_b+1+scan_length]):\n",
    "                    if aa == bb:\n",
    "                        ix_a = ix_a + offseta\n",
    "                        ix_b = ix_b + offsetb\n",
    "                        found_match = True\n",
    "                        #print(\"Found:\", aa,bb,ix_a,ix_b)\n",
    "                        break\n",
    "                if found_match:\n",
    "                    break\n",
    "            if not found_match:                \n",
    "                print(\"Failed: \" + ename, a, b, ix_a, len(wds1), ix_b, len(wds2))\n",
    "                failed_cnt +=1\n",
    "                break\n",
    "        else:            \n",
    "            ix_a += 1\n",
    "            ix_b += 1\n",
    "failed_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a coral is a living thing that lives in the ocean , it known for their bright color .\n",
      "1 the reason why they call it coral bleaching is because when it bleached it loses it color and becomes plain white stated in the article \" background : what is \" coral bleaching \" . \"\n",
      "2 there different explanations to what leads to differences in the rates of coral bleaching .\n",
      "3 one of these reasons is due to the trade wind happening in the ocean .\n",
      "4 when the trade winds reverse it cause the water temperature to change .\n",
      "5 due to this movement regions start to swell causing the sea - levels to rise .\n",
      "6 the article \" shifting trade winds \" it states that it more affected in the pacific ocean .\n",
      "7 as stated in the article \" what is coral bleaching \" saying that the pacific ocean is where coral bleaching is more done .\n",
      "8 another reason that explains the rate of coral bleaching is the zooxanthellage which has a symbiotic relationship with coral .\n",
      "9 when the coral happens to be bleached the zooxanthellae gets affected and makes the coral die easier since it is a living thing , based inthe article \" coral and zooxanthellae . \"\n"
     ]
    }
   ],
   "source": [
    "e = essay2parsed[\"EBA1415_KYNS_3_CB_ES-05384\"]\n",
    "for sent_ix, sent in enumerate(e.sentences):\n",
    "    wds = []\n",
    "    for wd,tags in sent:\n",
    "        wds.append(wd)\n",
    "    print(sent_ix, \" \".join(wds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a coral is a living thing that lives in the ocean , it known for their bright color .\n",
      "1 the reason why they call it coral bleaching is because when it bleached it loses it color and becomes plain white stated in the article '' background : what is '' coral bleaching '' . ''\n",
      "2 there different explanations to what leads to differences in the rates of coral bleaching .\n",
      "3 one of these reasons is due to the trade wind happening in the ocean .\n",
      "4 when the trade winds reverse it cause the water temperature to change .\n",
      "5 due to this movement regions start to swell causing the sea - levels to rise .\n",
      "6 the article '' shifting trade winds '' it states that it more affected in the pacific ocean .\n",
      "7 as stated in the article '' what is coral bleaching '' saying that the pacific ocean is where coral bleaching is more done .\n",
      "8 another reason that explains the rate of coral bleaching is the zooxanthellage which has a symbiotic relationship with coral .\n",
      "9 when the coral happens to be bleached the zooxanthellae gets affected and makes the coral die easier since it is a living thing , based inthe article '' coral and zooxanthellae . ''\n"
     ]
    }
   ],
   "source": [
    "e = essay2tagged[\"EBA1415_KYNS_3_CB_ES-05384\"]\n",
    "for sent_ix, sent in enumerate(e):\n",
    "    wds = []\n",
    "    for wd,tags in sent:\n",
    "        wds.append(wd)\n",
    "    print(sent_ix, \" \".join(wds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ename, tagged_essay in essay2tagged.items():\n",
    "    assert ename in essay2parsed\n",
    "    essay = essay2parsed[ename]\n",
    "         \n",
    "    wds1 = []\n",
    "    ix2_wd_sent_ix = {}\n",
    "    ix = 0\n",
    "    for sent_ix, sent in enumerate(essay.sentences):\n",
    "        for wd_ix, (wd,tags) in enumerate(sent):\n",
    "            ix2_wd_sent_ix[len(wds1)] = (sent_ix, wd_ix)\n",
    "            wds1.append(wd)\n",
    "\n",
    "    wds2 = []\n",
    "    for sent in tagged_essay:\n",
    "        for wd,tag_dict in sent:\n",
    "            if \"COREF_PHRASE\" in tag_dict:\n",
    "                #print(\"Found\")\n",
    "                wds2.append(wd)\n",
    "            \n",
    "    ix_a, ix_b = 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
