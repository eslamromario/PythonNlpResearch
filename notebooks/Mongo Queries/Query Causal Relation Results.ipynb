{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymongo\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient()\n",
    "db = client.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_by(df, bycols, agg_map):\n",
    "    \"\"\"\n",
    "\n",
    "    @param df:      DataFrame\n",
    "    @param bycols:  str or list\n",
    "                        Column(s) to group by\n",
    "    @param agg_map: dictionary or list of 2-tuples\n",
    "                        Mapping from column to aggregate function e.g. [(\"city\", \"count\"), (\"salary\", \"mean\"]\n",
    "    @return:        DataFrame\n",
    "                        Flattened dataframe, with multi-level index removed\n",
    "    \"\"\"\n",
    "    grps = []\n",
    "    if type(bycols) == str:\n",
    "        bycols = [bycols]\n",
    "\n",
    "    if type(agg_map) == dict:\n",
    "        agg_map = agg_map.items()\n",
    "\n",
    "    for k,v in agg_map:\n",
    "        grp = df[bycols + [k]].groupby(bycols, ).agg(v)\n",
    "        grp.reset_index(inplace=True)\n",
    "        grp[\"%s(%s)\" % (v,k)] = grp[k]\n",
    "        del grp[k]\n",
    "        grps.append(grp)\n",
    "\n",
    "    m = grps[0]\n",
    "    for grp in grps[1:]:\n",
    "        m = pd.merge(m, grp, on=bycols, how=\"inner\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bson.son import SON # needed to ensure dictionary is ordered (python default is not)\n",
    "import hashlib\n",
    "\n",
    "def hash_feats(fts):\n",
    "    vals = fts.values\n",
    "    joined = \"|\".join(map(lambda s: str(s),vals)).encode('utf-8') \n",
    "    return hashlib.sha224(joined).hexdigest()\n",
    "\n",
    "def get_df_sorted_by_f1score(collection, params=None, filter_cols=True):\n",
    "    if not params:\n",
    "        params = []\n",
    "    if type(params) == str:\n",
    "        params = params.split(\",\")\n",
    "    \n",
    "    project = {\n",
    "            \"weighted_f1_score\":\"$WEIGHTED_MEAN_CONCEPT_CODES.f1_score\",\n",
    "            \"micro_f1_score\":  \"$MICRO_F1.f1_score\",\n",
    "            \"micro_recall\":    \"$MICRO_F1.recall\",\n",
    "            \"micro_precision\": \"$MICRO_F1.precision\",\n",
    "    \n",
    "    # PARAMETERS            \n",
    "            \"window_size\":    \"$parameters.window_size\",\n",
    "            \"feats\":          \"$parameters.extractors\",\n",
    "            \"count\": {        \"$size\" : \"$parameters.extractors\" },\n",
    "            \"asof\" :          \"$asof\",\n",
    "            \"_id\":1\n",
    "    }\n",
    "    \n",
    "    # No count for HMM\n",
    "    if \"_hmm\" in collection.lower():\n",
    "        del project[\"count\"]\n",
    "    \n",
    "    for param in params:\n",
    "        project[param] = \"$parameters.\" + param\n",
    "\n",
    "    feats_pipeline = [{\n",
    "        \"$project\": project\n",
    "    },\n",
    "    {\n",
    "        \"$match\":{\n",
    "            \"micro_f1_score\": { \"$exists\" : True }        \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\":{\n",
    "            \"micro_f1_score\": -1\n",
    "        }\n",
    "    },\n",
    "    ]\n",
    "    \n",
    "    rows = [row for row in db[collection].aggregate(feats_pipeline)]\n",
    "    df = pd.DataFrame(rows).sort_values(\"micro_f1_score\", ascending=False)\n",
    "    if params:\n",
    "        df[\"hs_params\"] = df[params].apply(hash_feats, axis=1)\n",
    "        \n",
    "    if filter_cols:\n",
    "        cols = [\"micro_f1_score\", \"micro_recall\" ,\"micro_precision\" ] + params\n",
    "        return df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Metrics import rpf1a_from_tp_fp_tn_fn\n",
    "from collections import defaultdict\n",
    "\n",
    "def tally_counts(r, filter):\n",
    "    tally = defaultdict(int)\n",
    "    for k,v in r.items():\n",
    "        if filter(k):\n",
    "            for prop in \"tp,tn,fp,fn\".split(\",\"):\n",
    "                tally[prop] += v[prop]\n",
    "    return tally\n",
    "\n",
    "def get_causal_relation_metrics(collection, params, include_concept_codes=True):\n",
    "    dicts = []\n",
    "    for r in db[collection].find({}):\n",
    "        d = {}\n",
    "        cr_counts = tally_counts(r, lambda c: \"->\" in c)\n",
    "        (rec, p, cr_f1, a) = rpf1a_from_tp_fp_tn_fn(cr_counts[\"tp\"],cr_counts[\"fp\"],cr_counts[\"tn\"],cr_counts[\"fn\"])\n",
    "        d[\"cr_micro_f1\"] = cr_f1\n",
    "        d[\"cr_micro_rec\"]  = rec\n",
    "        d[\"cr_micro_prec\"] = p\n",
    "        if include_concept_codes:\n",
    "            concept_counts = tally_counts(r, lambda c: c[0].isdigit())\n",
    "            (rec, p, concept_f1, a) = rpf1a_from_tp_fp_tn_fn(concept_counts[\"tp\"],concept_counts[\"fp\"],concept_counts[\"tn\"],concept_counts[\"fn\"])\n",
    "            d[\"concept_micro_f1\"] = concept_f1\n",
    "            d[\"concept_micro_rec\"]  = rec\n",
    "            d[\"concept_micro_prec\"] = p\n",
    "        parms = r[\"parameters\"]\n",
    "        for p in params:\n",
    "            d[p] = parms[p]\n",
    "        dicts.append(d)\n",
    "    df = pd.DataFrame(dicts)\n",
    "    fields = (\"cr_micro_f1,cr_micro_rec,cr_micro_prec,concept_micro_f1,concept_micro_rec,concept_micro_prec,\" + \",\".join(params)).split(\",\")\n",
    "    if not include_concept_codes:\n",
    "        fields = [f for f in fields if \"concept\" not in f]\n",
    "    return df[fields].sort_values(\"cr_micro_f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def round_data(df, places=3):\n",
    "    df_copy = df.copy()\n",
    "    fmt_str = \"{0:.\" + str(places) + \"f}\"\n",
    "    cols = set([v for v in df_copy.columns.values if \"micro_\" in v])\n",
    "    for c in cols:\n",
    "        df_copy[c] = df[c].apply(lambda d: fmt_str.format(d))  \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Relevance - CR and Concept Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coral Bleaching\n",
    "(no skin cancer results for this experiment)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params = \"merge_mode,num_rnns,use_pretrained_embedding,bi-directional,hidden_size\"\n",
    "df = get_causal_relation_metrics(\"CR_CB_TAGGING_TD_RNN\", params.split(\",\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params = \"merge_mode,num_rnns,use_pretrained_embedding,bi-directional,hidden_size\"\n",
    "df = get_causal_relation_metrics(\"CR_CB_TAGGING_VD_RNN\", params.split(\",\"))\n",
    "df.sort_values(\"cr_micro_f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">No longer valid - not included in final experiments</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Most Common Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coral Bleaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = \"merge_mode,num_rnns,use_pretrained_embedding,bi-directional,hidden_size\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>merge_mode</th>\n",
       "      <th>num_rnns</th>\n",
       "      <th>use_pretrained_embedding</th>\n",
       "      <th>bi-directional</th>\n",
       "      <th>hidden_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.8714</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8054</td>\n",
       "      <td>0.8128</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7852</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.8007</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7418</td>\n",
       "      <td>0.7381</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7169</td>\n",
       "      <td>0.7509</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision merge_mode  num_rnns  \\\n",
       "0         0.8688       0.8714          0.8662        sum         2   \n",
       "1         0.8054       0.8128          0.7980        sum         2   \n",
       "2         0.7852       0.7980          0.7729        sum         1   \n",
       "3         0.7542       0.8007          0.7128        sum         1   \n",
       "4         0.7418       0.7381          0.7455        sum         2   \n",
       "5         0.7169       0.7509          0.6858        sum         1   \n",
       "\n",
       "  use_pretrained_embedding bi-directional  hidden_size  \n",
       "0                     True           True          256  \n",
       "1                     True           True          128  \n",
       "2                     True           True          256  \n",
       "3                     True           True          128  \n",
       "4                     True           True           64  \n",
       "5                     True           True           64  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_sorted_by_f1score(\"CR_CB_TAGGING_TD_MOST_COMMON_TAG_RNN\", params)\n",
    "round_data(df,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>merge_mode</th>\n",
       "      <th>num_rnns</th>\n",
       "      <th>use_pretrained_embedding</th>\n",
       "      <th>bi-directional</th>\n",
       "      <th>hidden_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.6949</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6731</td>\n",
       "      <td>0.6803</td>\n",
       "      <td>0.6661</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6498</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6358</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.5978</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6351</td>\n",
       "      <td>0.6540</td>\n",
       "      <td>0.6173</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6342</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.6404</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision merge_mode  num_rnns  \\\n",
       "0         0.6798       0.6949          0.6653        sum         2   \n",
       "1         0.6731       0.6803          0.6661        sum         2   \n",
       "2         0.6498       0.6564          0.6433        sum         1   \n",
       "3         0.6358       0.6790          0.5978        sum         1   \n",
       "4         0.6351       0.6540          0.6173        sum         1   \n",
       "5         0.6342       0.6281          0.6404        sum         2   \n",
       "\n",
       "  use_pretrained_embedding bi-directional  hidden_size  \n",
       "0                     True           True          256  \n",
       "1                     True           True          128  \n",
       "2                     True           True          256  \n",
       "3                     True           True          128  \n",
       "4                     True           True           64  \n",
       "5                     True           True           64  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_sorted_by_f1score(\"CR_CB_TAGGING_VD_MOST_COMMON_TAG_RNN\", params)\n",
    "round_data(df,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>merge_mode</th>\n",
       "      <th>num_rnns</th>\n",
       "      <th>use_pretrained_embedding</th>\n",
       "      <th>bi-directional</th>\n",
       "      <th>hidden_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision merge_mode  num_rnns  \\\n",
       "0         0.6764       0.6561          0.6980        sum         2   \n",
       "\n",
       "  use_pretrained_embedding bi-directional  hidden_size  \n",
       "0                     True           True          256  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_sorted_by_f1score(\"TEST_CR_CB_TAGGING_VD_MOST_COMMON_TAG_RNN\", params)\n",
    "round_data(df,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skin Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>merge_mode</th>\n",
       "      <th>num_rnns</th>\n",
       "      <th>use_pretrained_embedding</th>\n",
       "      <th>bi-directional</th>\n",
       "      <th>hidden_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8718</td>\n",
       "      <td>0.8549</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>0.8520</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8494</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8423</td>\n",
       "      <td>0.8369</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8325</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7996</td>\n",
       "      <td>0.8188</td>\n",
       "      <td>0.7812</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision merge_mode  num_rnns  \\\n",
       "0         0.8718       0.8549          0.8894        sum         2   \n",
       "1         0.8527       0.8534          0.8520        sum         2   \n",
       "2         0.8494       0.8380          0.8610        sum         2   \n",
       "3         0.8423       0.8369          0.8478        sum         1   \n",
       "4         0.8325       0.8569          0.8095        sum         1   \n",
       "5         0.7996       0.8188          0.7812        sum         1   \n",
       "\n",
       "  use_pretrained_embedding bi-directional  hidden_size  \n",
       "0                     True           True          256  \n",
       "1                     True           True          128  \n",
       "2                     True           True           64  \n",
       "3                     True           True          256  \n",
       "4                     True           True          128  \n",
       "5                     True           True           64  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_sorted_by_f1score(\"CR_SC_TAGGING_TD_MOST_COMMON_TAG_RNN\", params)\n",
    "round_data(df,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>merge_mode</th>\n",
       "      <th>num_rnns</th>\n",
       "      <th>use_pretrained_embedding</th>\n",
       "      <th>bi-directional</th>\n",
       "      <th>hidden_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7686</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.7765</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7497</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7521</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7418</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.7134</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7295</td>\n",
       "      <td>0.7499</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision merge_mode  num_rnns  \\\n",
       "0         0.7686       0.7608          0.7765        sum         2   \n",
       "1         0.7562       0.7628          0.7497        sum         2   \n",
       "2         0.7539       0.7545          0.7533        sum         1   \n",
       "3         0.7521       0.7415          0.7631        sum         2   \n",
       "4         0.7418       0.7726          0.7134        sum         1   \n",
       "5         0.7295       0.7499          0.7102        sum         1   \n",
       "\n",
       "  use_pretrained_embedding bi-directional  hidden_size  \n",
       "0                     True           True          256  \n",
       "1                     True           True          128  \n",
       "2                     True           True          256  \n",
       "3                     True           True           64  \n",
       "4                     True           True          128  \n",
       "5                     True           True           64  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_sorted_by_f1score(\"CR_SC_TAGGING_VD_MOST_COMMON_TAG_RNN\", params)\n",
    "round_data(df,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>merge_mode</th>\n",
       "      <th>num_rnns</th>\n",
       "      <th>use_pretrained_embedding</th>\n",
       "      <th>bi-directional</th>\n",
       "      <th>hidden_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7918</td>\n",
       "      <td>0.7979</td>\n",
       "      <td>0.7859</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision merge_mode  num_rnns  \\\n",
       "0         0.7918       0.7979          0.7859        sum         2   \n",
       "\n",
       "  use_pretrained_embedding bi-directional  hidden_size  \n",
       "0                     True           True          256  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_sorted_by_f1score(\"TEST_CR_SC_TAGGING_VD_MOST_COMMON_TAG_RNN\", params)\n",
    "round_data(df,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stacked Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coral Bleaching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>dual</th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>max_feats</th>\n",
       "      <th>min_feats</th>\n",
       "      <th>average_feats</th>\n",
       "      <th>binary_feats</th>\n",
       "      <th>combo_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.7742</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7412</td>\n",
       "      <td>0.7106</td>\n",
       "      <td>0.7745</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7407</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>0.7747</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7387</td>\n",
       "      <td>0.7072</td>\n",
       "      <td>0.7733</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7386</td>\n",
       "      <td>0.7068</td>\n",
       "      <td>0.7733</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision   dual penalty      C max_feats  \\\n",
       "0         0.7415       0.7113          0.7742  False      l1  100.0     False   \n",
       "1         0.7412       0.7106          0.7745  False      l2  100.0     False   \n",
       "2         0.7407       0.7096          0.7747  False      l1   10.0     False   \n",
       "3         0.7387       0.7072          0.7733  False      l2   10.0     False   \n",
       "4         0.7386       0.7068          0.7733   True      l2   10.0     False   \n",
       "\n",
       "  min_feats average_feats binary_feats combo_feats  \n",
       "0     False         False         True        True  \n",
       "1     False         False         True        True  \n",
       "2     False         False         True        True  \n",
       "3     False         False         True        True  \n",
       "4     False         False         True        True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparams = \"dual,penalty,C,max_feats,min_feats,average_feats,binary_feats,combo_feats\".split(\",\")\n",
    "df = get_df_sorted_by_f1score(\"CR_CB_STACKED_TD\", sparams)\n",
    "round_data(df,4).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>dual</th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>max_feats</th>\n",
       "      <th>min_feats</th>\n",
       "      <th>average_feats</th>\n",
       "      <th>binary_feats</th>\n",
       "      <th>combo_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.7447</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.7447</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.7447</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6930</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>0.7336</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision   dual penalty    C max_feats  \\\n",
       "0         0.6946       0.6560          0.7380  False      l1  1.0     False   \n",
       "3         0.6936       0.6490          0.7447  False      l2  1.0     False   \n",
       "1         0.6936       0.6490          0.7447   True      l2  1.0     False   \n",
       "2         0.6936       0.6490          0.7447   True      l2  1.0     False   \n",
       "4         0.6930       0.6567          0.7336  False      l1  0.5     False   \n",
       "\n",
       "  min_feats average_feats binary_feats combo_feats  \n",
       "0     False         False         True        True  \n",
       "3     False         False         True        True  \n",
       "1     False         False         True        True  \n",
       "2     False         False         True        True  \n",
       "4     False         False         True        True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_sorted_by_f1score(\"CR_CB_STACKED_VD\", sparams)\n",
    "round_data(df,4).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>dual</th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>max_feats</th>\n",
       "      <th>min_feats</th>\n",
       "      <th>average_feats</th>\n",
       "      <th>binary_feats</th>\n",
       "      <th>combo_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7038</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>0.7359</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision  dual penalty    C max_feats  \\\n",
       "0         0.7038       0.6745          0.7359  True      l2  0.5      True   \n",
       "\n",
       "  min_feats average_feats binary_feats combo_feats  \n",
       "0     False          True        False        True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_sorted_by_f1score(\"TEST_CR_CB_STACKED_VD\", sparams)\n",
    "round_data(df,4).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skin Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>dual</th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>max_feats</th>\n",
       "      <th>min_feats</th>\n",
       "      <th>average_feats</th>\n",
       "      <th>binary_feats</th>\n",
       "      <th>combo_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8007</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.8504</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.7492</td>\n",
       "      <td>0.8473</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.7459</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7891</td>\n",
       "      <td>0.7407</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7888</td>\n",
       "      <td>0.7407</td>\n",
       "      <td>0.8436</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision   dual penalty      C max_feats  \\\n",
       "0         0.8007       0.7566          0.8504  False      l1  100.0      True   \n",
       "1         0.7952       0.7492          0.8473  False      l2  100.0      True   \n",
       "2         0.7929       0.7459          0.8464  False      l1   10.0      True   \n",
       "3         0.7891       0.7407          0.8444  False      l1    5.0      True   \n",
       "4         0.7888       0.7407          0.8436  False      l2   10.0      True   \n",
       "\n",
       "  min_feats average_feats binary_feats combo_feats  \n",
       "0     False          True        False        True  \n",
       "1     False          True        False        True  \n",
       "2     False          True        False        True  \n",
       "3     False          True        False        True  \n",
       "4     False          True        False        True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparams = \"dual,penalty,C,max_feats,min_feats,average_feats,binary_feats,combo_feats\".split(\",\")\n",
    "df = get_df_sorted_by_f1score(\"CR_SC_STACKED_TD\", sparams)\n",
    "round_data(df,4).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>dual</th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>max_feats</th>\n",
       "      <th>min_feats</th>\n",
       "      <th>average_feats</th>\n",
       "      <th>binary_feats</th>\n",
       "      <th>combo_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8232</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8232</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8232</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8232</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7630</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.8216</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision   dual penalty    C max_feats  \\\n",
       "0         0.7632       0.7113          0.8232   True      l2  1.0      True   \n",
       "1         0.7632       0.7113          0.8232   True      l2  1.0     False   \n",
       "2         0.7632       0.7113          0.8232   True      l2  1.0      True   \n",
       "3         0.7632       0.7113          0.8232  False      l2  1.0      True   \n",
       "4         0.7630       0.7121          0.8216   True      l2  1.0      True   \n",
       "\n",
       "  min_feats average_feats binary_feats combo_feats  \n",
       "0     False          True        False        True  \n",
       "1      True          True        False        True  \n",
       "2     False          True        False        True  \n",
       "3     False          True        False        True  \n",
       "4     False          True         True        True  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparams = \"dual,penalty,C,max_feats,min_feats,average_feats,binary_feats,combo_feats\".split(\",\")\n",
    "df = get_df_sorted_by_f1score(\"CR_SC_STACKED_VD\", sparams)\n",
    "round_data(df,4).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>dual</th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>max_feats</th>\n",
       "      <th>min_feats</th>\n",
       "      <th>average_feats</th>\n",
       "      <th>binary_feats</th>\n",
       "      <th>combo_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision  dual penalty     C max_feats  \\\n",
       "0         0.7762       0.7236          0.8372  True      l2  10.0      True   \n",
       "\n",
       "  min_feats average_feats binary_feats combo_feats  \n",
       "0     False         False         True        True  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparams = \"dual,penalty,C,max_feats,min_feats,average_feats,binary_feats,combo_feats\".split(\",\")\n",
    "df = get_df_sorted_by_f1score(\"TEST_CR_SC_STACKED_TD\", sparams)\n",
    "round_data(df,4).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Top Validation Metrics By Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coral Bleaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb_collections = [\n",
    "    \"CR_CB_TAGGING_VD_MOST_COMMON_TAG_RNN\", \n",
    "    \"CR_CB_STACKED_VD\",\n",
    "    \"CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_VD\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_VD</td>\n",
       "      <td>0.703519</td>\n",
       "      <td>0.755344</td>\n",
       "      <td>0.658350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CR_CB_STACKED_VD</td>\n",
       "      <td>0.694611</td>\n",
       "      <td>0.738024</td>\n",
       "      <td>0.656021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CR_CB_TAGGING_VD_MOST_COMMON_TAG_RNN</td>\n",
       "      <td>0.679792</td>\n",
       "      <td>0.665287</td>\n",
       "      <td>0.694943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Algo  micro_f1_score  micro_precision  \\\n",
       "2  CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_VD        0.703519         0.755344   \n",
       "1                        CR_CB_STACKED_VD        0.694611         0.738024   \n",
       "0    CR_CB_TAGGING_VD_MOST_COMMON_TAG_RNN        0.679792         0.665287   \n",
       "\n",
       "   micro_recall  \n",
       "2      0.658350  \n",
       "1      0.656021  \n",
       "0      0.694943  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for coll in cb_collections:\n",
    "    df = get_df_sorted_by_f1score(coll, \"\")\n",
    "    dct = df.iloc[0].to_dict()\n",
    "    dct[\"Algo\"] = coll\n",
    "    rows.append(dct)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.sort_values(\"micro_f1_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skin Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CR_SC_TAGGING_VD_MOST_COMMON_TAG_RNN</td>\n",
       "      <td>0.768559</td>\n",
       "      <td>0.776524</td>\n",
       "      <td>0.760756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CR_SC_STACKED_VD</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.823174</td>\n",
       "      <td>0.711299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Algo  micro_f1_score  micro_precision  \\\n",
       "0  CR_SC_TAGGING_VD_MOST_COMMON_TAG_RNN        0.768559         0.776524   \n",
       "1                      CR_SC_STACKED_VD        0.763158         0.823174   \n",
       "\n",
       "   micro_recall  \n",
       "0      0.760756  \n",
       "1      0.711299  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for coll in cb_collections[:-1]: # -1 as we don't yet have this for the parser model\n",
    "    coll = coll.replace(\"CB\", \"SC\")\n",
    "    df = get_df_sorted_by_f1score(coll, \"\")\n",
    "    dct = df.iloc[0].to_dict()\n",
    "    dct[\"Algo\"] = coll\n",
    "    rows.append(dct)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.sort_values(\"micro_f1_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_CR_CB_STACKED_VD</td>\n",
       "      <td>0.703833</td>\n",
       "      <td>0.735883</td>\n",
       "      <td>0.674457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_CR_CB_TAGGING_VD_MOST_COMMON_TAG_RNN</td>\n",
       "      <td>0.676420</td>\n",
       "      <td>0.698046</td>\n",
       "      <td>0.656093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Algo  micro_f1_score  micro_precision  \\\n",
       "1                      TEST_CR_CB_STACKED_VD        0.703833         0.735883   \n",
       "0  TEST_CR_CB_TAGGING_VD_MOST_COMMON_TAG_RNN        0.676420         0.698046   \n",
       "\n",
       "   micro_recall  \n",
       "1      0.674457  \n",
       "0      0.656093  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Still need this for RNN and the parser model\n",
    "rows = []\n",
    "for coll in collections[:-1]:\n",
    "    coll = \"TEST_\" + coll\n",
    "    df = get_df_sorted_by_f1score(coll, \"\")\n",
    "    dct = df.iloc[0].to_dict()\n",
    "    dct[\"Algo\"] = coll\n",
    "    rows.append(dct)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.sort_values(\"micro_f1_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_CR_SC_TAGGING_VD_MOST_COMMON_TAG_RNN</td>\n",
       "      <td>0.791833</td>\n",
       "      <td>0.785903</td>\n",
       "      <td>0.797853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_CR_SC_STACKED_VD</td>\n",
       "      <td>0.764622</td>\n",
       "      <td>0.816244</td>\n",
       "      <td>0.719141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Algo  micro_f1_score  micro_precision  \\\n",
       "0  TEST_CR_SC_TAGGING_VD_MOST_COMMON_TAG_RNN        0.791833         0.785903   \n",
       "1                      TEST_CR_SC_STACKED_VD        0.764622         0.816244   \n",
       "\n",
       "   micro_recall  \n",
       "0      0.797853  \n",
       "1      0.719141  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Still need this for RNN and the parser model\n",
    "rows = []\n",
    "for coll in collections[:-1]:\n",
    "    coll = \"TEST_\" + coll\n",
    "    coll = coll.replace(\"CB\", \"SC\")\n",
    "    df = get_df_sorted_by_f1score(coll, \"\")\n",
    "    dct = df.iloc[0].to_dict()\n",
    "    dct[\"Algo\"] = coll\n",
    "    rows.append(dct)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.sort_values(\"micro_f1_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
