{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "from collections import defaultdict\n",
    "\n",
    "class BinaryRelation(object):\n",
    "    def __init__(self, head, relation, child):\n",
    "        self.relation = relation\n",
    "        self.head = head\n",
    "        self.child = \"None\" if (child is None or child.strip() == \"\") else child\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"[%s]%s -> %s\" % (self.relation, self.head, self.child)\n",
    "\n",
    "class Relation(object):\n",
    "\n",
    "    def __init__(self, head, relation, children):\n",
    "        self.relation = relation\n",
    "        self.head = head\n",
    "        self.children = children\n",
    "        self.__binary_relns_ = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        skids = \",\".join(self.children)\n",
    "        return \"[%s]%s -> %s\" % (self.relation, self.head, skids)\n",
    "\n",
    "    def binary_relations(self):\n",
    "        if self.__binary_relns_ is not None:\n",
    "            return self.__binary_relns_\n",
    "        rels = []\n",
    "        if len(self.children) == 0:\n",
    "            rels.append(BinaryRelation(self.head, self.relation, None))\n",
    "        else:\n",
    "            for ch in self.children:\n",
    "                rels.append(BinaryRelation(self.head, self.relation, ch))\n",
    "        self.__binary_relns_ = rels\n",
    "        return rels\n",
    "\n",
    "# Python 3.x fix - emulate removed unicode function\n",
    "# https://stackoverflow.com/questions/6812031/how-to-make-unicode-string-with-python3\n",
    "def unicode(s):\n",
    "    return str(s)\n",
    "\n",
    "class Parser(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nlp = English()\n",
    "\n",
    "    def parse(self, tokens):\n",
    "        stokens = unicode(\" \".join(tokens))\n",
    "\n",
    "        tokens = self.__tokenize_(stokens)\n",
    "        children_for_head = defaultdict(set)\n",
    "        for token in tokens:\n",
    "            children_for_head[token.head.i].add(token.string.strip())\n",
    "\n",
    "        relations = []\n",
    "        for token in tokens:\n",
    "            kids = children_for_head[token.i]\n",
    "            relations.append(Relation(token.head.string, token.dep_, list(kids)))\n",
    "\n",
    "        assert len(relations) == len(tokens), \"There are a different number of tokens to relations\"\n",
    "        return relations\n",
    "\n",
    "    def pos_tag(self, tokens):\n",
    "        stokens = unicode(\" \".join(tokens))\n",
    "        tokens = self.__tokenize_(stokens)\n",
    "        return list(map(lambda t: t.pos_, tokens))\n",
    "\n",
    "    def pos_tag2(self, tokens):\n",
    "        stokens = unicode(\" \".join(tokens))\n",
    "        tokens = self.__tokenize_(stokens)\n",
    "        return list(map(lambda t: t.tag_, tokens))\n",
    "\n",
    "    def brown_cluster(self, tokens):\n",
    "        stokens = unicode(\" \".join(tokens))\n",
    "        tokens = self.__tokenize_(stokens)\n",
    "        return list(map(lambda t: str(t.cluster), tokens))\n",
    "\n",
    "    def dep_vector(self, tokens):\n",
    "        stokens = unicode(\" \".join(tokens))\n",
    "        tokens = self.__tokenize_(stokens)\n",
    "        # yields a list of (300,) dimensional numpy arrays\n",
    "        return list(map(lambda t: t.repvec, tokens))\n",
    "\n",
    "    def __tokenize_(self, sentence):\n",
    "        return list(self.nlp(sentence, tag=True, parse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]The  -> The, []increasing  -> increasing, []levels  -> levels, []of  -> of, []carbon  -> carbon, []dioxide  -> dioxide, []caused  -> caused, []coral  -> coral, []bleaching -> bleaching]\n",
      "['', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "parser = Parser()\n",
    "split = \"The increasing levels of carbon dioxide caused coral bleaching\".split(\" \")\n",
    "parsed = parser.parse(split)\n",
    "print(parsed)\n",
    "\n",
    "tags = parser.pos_tag(split)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[]The  -> The,\n",
       " []increasing  -> increasing,\n",
       " []levels  -> levels,\n",
       " []of  -> of,\n",
       " []carbon  -> carbon,\n",
       " []dioxide  -> dioxide,\n",
       " []caused  -> caused,\n",
       " []coral  -> coral,\n",
       " []bleaching -> bleaching]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The increasing levels of carbon dioxide caused coral bleaching\"\n",
    "tokens = sentence.split(\" \")\n",
    "parser.parse(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '0', '0', '0', '0', '0']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.brown_cluster(\"the dog sat on the tree\".split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'increasing',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'carbon',\n",
       " 'dioxide',\n",
       " 'caused',\n",
       " 'coral',\n",
       " 'bleaching']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[u'goat'].cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
