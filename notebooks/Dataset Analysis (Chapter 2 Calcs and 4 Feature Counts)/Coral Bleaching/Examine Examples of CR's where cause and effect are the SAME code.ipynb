{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/simon.hughes/anaconda/envs/phd_py36/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "from Settings import Settings\n",
    "import dill\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "training_pickled = settings.data_directory + \"CoralBleaching/Thesis_Dataset/training.pl\"\n",
    "# NOTE: These predictions are generated from the \"./notebooks/SEARN/Keras - Train Tagger and Save CV Predictions For Word Tags.ipynb\" notebook\n",
    "# used as inputs to parsing model\n",
    "rnn_predictions_folder = root_folder + \"Predictions/Bi-LSTM-4-SEARN/\"\n",
    "\n",
    "train_fname = rnn_predictions_folder + \"essays_train_bi_directional-True_hidden_size-256_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "(1154, 'files found')\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_AEKD_4_CB_ES-05571.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_AEKD_4_CB_ES-05904.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_BGJD_1_CB_ES-05733.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_ERSK_7_CB_ES-05798.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_KYLS_5_CB_ES-05671.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_LRJE_5_CB_ES-05128.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_2_CB_ES-05612.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_2_CB_ES-05617.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_4_CB_ES-05632.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_4_CB_ES-05640.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SWSP_4_CB_ES-05459.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_1_CB_ES-05484.ann file as .txt file is no essay. //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_1_CB_ES-05485.ann file as .txt file is no essay.  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_2_CB_ES-05548.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFMV_3_CB_ES-05845.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_11_CB_ES-05715.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_11_CB_ES-05721.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_2_CB_ES-06128.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_2_CB_ES-06132.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRKM_1_CB_ES-05025.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRKM_1_CB_ES-05030.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_2_CB_ES-06140.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_910_CB_ES-06149.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_910_CB_ES-06153.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTKP_7-8_CB_ES-06174.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415post_TWNB_2_CB_ES-04948.ann file as .txt file is no essay.'\n",
      "1128 essays processed\n"
     ]
    }
   ],
   "source": [
    "from BrattEssay import load_bratt_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "#essays = load_bratt_essays(settings.data_directory + \"SkinCancer/EBA1415_Merged/\")\n",
    "folder = settings.data_directory + \"CoralBleaching/BrattData/EBA1415_Merged/\"\n",
    "essays = load_bratt_essays(folder)\n",
    "\n",
    "wd_sent_freq = defaultdict(int)\n",
    "all_codes = set()\n",
    "#Stores all words for the spelling corrector\n",
    "words = []\n",
    "all_sentences = []\n",
    "sentencesForCode = defaultdict(list)\n",
    "for essay in essays:\n",
    "    for sentence in essay.tagged_sentences:\n",
    "        wdsInSent = set()\n",
    "        codes4sentence = set()\n",
    "        sent = []\n",
    "        for w, tags in sentence:\n",
    "            words.append(w)\n",
    "            all_codes.update(tags)\n",
    "            codes4sentence.update(tags)\n",
    "            if w not in wdsInSent:\n",
    "                wdsInSent.add(w)\n",
    "                wd_sent_freq[w] += 1\n",
    "            sent.append(w)\n",
    "        all_sentences.append(sent)\n",
    "        for code in codes4sentence:\n",
    "            sentencesForCode[code].append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Stats over the Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_tag_freq(train_tagged_essays):\n",
    "    stag_freq = defaultdict(int)\n",
    "    unique_words = set()\n",
    "    for essay in train_tagged_essays:\n",
    "        for sentence in essay.sentences:\n",
    "            for word, tags in sentence:\n",
    "                for tag in tags:\n",
    "                    stag_freq[tag] += 1\n",
    "    return stag_freq\n",
    "\n",
    "\n",
    "def get_tag_2_sent(train_tagged_essays):\n",
    "    tag2sent = defaultdict(list)\n",
    "    sent2tags = defaultdict(set)\n",
    "    sent_ix = 0\n",
    "    for essay in train_tagged_essays:\n",
    "        for sentence in essay.sentences:\n",
    "            sent_ix += 1\n",
    "            unique_sent_tags = set()\n",
    "            sent_words = []\n",
    "            for word, tags in sentence:\n",
    "                sent_words.append(word)\n",
    "                for tag in tags:\n",
    "                    unique_sent_tags.add(tag)\n",
    "        \n",
    "            if unique_sent_tags and sent_words:\n",
    "                str_sent = str(sent_ix) + \": \" + \" \".join(sent_words)\n",
    "                sent2tags[str_sent] = unique_sent_tags\n",
    "                for tag in unique_sent_tags:\n",
    "                    tag2sent[tag].append(str_sent)                    \n",
    "    return tag2sent, sent2tags\n",
    "\n",
    "def get_cr_tags(train_tagged_essays, tag_essays_test):\n",
    "\n",
    "    tag_freq = get_tag_freq(train_tagged_essays, tag_essays_test)\n",
    "    crel_tags = list((t for t in tag_freq.keys() if (\"->\" in t) and\n",
    "                    not \"Anaphor\" in t and\n",
    "                    not \"other\" in t and\n",
    "                    not \"rhetorical\" in t and\n",
    "                    not \"factor\" in t and\n",
    "                    1 == 1\n",
    "                    ))\n",
    "    return crel_tags\n",
    "\n",
    "def is_cr_tag(t):    \n",
    "    return (\"->\" in t) and \\\n",
    "        not \"Anaphor\" in t and \\\n",
    "        not \"other\" in t and \\\n",
    "        not \"rhetorical\" in t and \\\n",
    "        not \"factor\" in t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2sent, sent2tags = get_tag_2_sent(pred_tagged_essays_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_freq = get_tag_freq(pred_tagged_essays_train)\n",
    "cr_tags = [t for t in tag_freq.keys() if is_cr_tag(t)]\n",
    "#cr_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_code_from_cr_part(cr_part):\n",
    "    return cr_part.lower().strip().replace(\"causer:\",\"\").replace(\"result:\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Causer:11->Result:11', 'Causer:50->Result:50'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_code_crs = set()\n",
    "for cr_tag in cr_tags:\n",
    "    left,right = cr_tag.split(\"->\")\n",
    "    left = get_code_from_cr_part(left)\n",
    "    right = get_code_from_cr_part(right)\n",
    "    if left == right:\n",
    "        same_code_crs.add(cr_tag)\n",
    "same_code_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Causer:11->Result:11\n",
      "['Causer:11->Result:11', 'Causer:3->Result:4']\n",
      "2738: balance between co2 and water temperature is also threaten by extreme storms .\n",
      "\n",
      "********************************************************************************\n",
      "Causer:50->Result:50\n",
      "['Causer:1->Result:50', 'Causer:50->Result:50']\n",
      "190: if the shifting trade winds make colors the corals will die and cause coral bleaching .\n",
      "\n",
      "['Causer:13->Result:50', 'Causer:50->Result:50']\n",
      "1859: if there isnt enough salinity need for coral health , they will die and change into white color .\n",
      "\n",
      "['Causer:5b->Result:50', 'Causer:50->Result:50']\n",
      "1942: it is 00 - 00 percent of their energy intake so the less energy easier for it to die and turn white .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cr_tag in same_code_crs:\n",
    "    print(\"*\" * 80)\n",
    "    print(cr_tag)\n",
    "    for i, sent in enumerate(tag2sent[cr_tag]):        \n",
    "        tags = sent2tags[sent]\n",
    "        cr_tags = [t for t in tags if is_cr_tag(t)]\n",
    "        print(cr_tags)\n",
    "        print(sent)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1: what leads to differences in the rates of coral bleaching .', {'50'}),\n",
       " ('3: coral bleaching shows bleaching and healthy bleaching event that makes coral vulnerable to disease and starvation .',\n",
       "  {'50'}),\n",
       " ('4: coral bleaching is almost noticeable in the pacific ocean .',\n",
       "  {'50', 'COMPILED'}),\n",
       " ('5: the part of coral called \" zooanthellae \" are not getting sunlight .',\n",
       "  {'5'}),\n",
       " ('6: and if they dont get or much sunlight they start to loses their color .',\n",
       "  {'5',\n",
       "   '50',\n",
       "   'Anaphor',\n",
       "   'Causer',\n",
       "   'Causer:5',\n",
       "   'Causer:5->Result:50',\n",
       "   'Result',\n",
       "   'Result:50',\n",
       "   'explicit'}),\n",
       " ('7: the reason why is because the \" zooanthellae . \" if not getting mixed up with carbon dioxide .',\n",
       "  {'4'}),\n",
       " ('9: also its a threats for us because means that more extreme storms are most likely to occurs .',\n",
       "  {'11'}),\n",
       " ('10: also the water us getting to salty .', {'13', 'COMPILED'}),\n",
       " ('11: what leads to different in the rates of coral bleaching is that INFREQUENT different types of INFREQUENT living within the coral polyps gives the coral their varying colors .',\n",
       "  {'50',\n",
       "   'Causer',\n",
       "   'Causer:7',\n",
       "   'Causer:7->Result:50',\n",
       "   'Result',\n",
       "   'Result:50',\n",
       "   'explicit'}),\n",
       " ('16: as water INFREQUENT increases , the amount of carbon dioxide in water decreases .',\n",
       "  {'3',\n",
       "   '4',\n",
       "   'Causer',\n",
       "   'Causer:3',\n",
       "   'Causer:3->Result:4',\n",
       "   'Result',\n",
       "   'Result:4',\n",
       "   'explicit'})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sent2tags.items())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
