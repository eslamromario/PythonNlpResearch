{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to play with the models exposed from Allen NLP library listed here: https://github.com/allenai/allennlp/tree/v0.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Install docker for mac - https://docs.docker.com/docker-for-mac/install/\n",
    "2. Download and run the container, making sure to map port 8000 to port 8000 to expose it outside of docker\n",
    " * ```docker run -it --rm -p 8000:8000 allennlp/allennlp```\n",
    "3. Within the image, run the webserver on port 8000\n",
    " * `allennlp/run serve --port 8000`\n",
    "4.  Now in your browser, hit http:/localhost:8000 for the webserver\n",
    "\n",
    "See https://github.com/allenai/allennlp/tree/master/allennlp/service for basic documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Saved Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will want to run the web server once, and while it's running, save the container to a new image so that the models are stored within it, and don't need downloading each time. To do this, with the container still running, get the container id using `docker ps`. Then run:\n",
    "\n",
    "`docker commit <containerid> allennlp_test/1.0`\n",
    "\n",
    "To commit the container's state to a new image called allennelp_test/1.0. \n",
    "Then kill the current container, and run the new image:\n",
    "\n",
    "`docker run --it --rm -p 8000:8000 allennlp_test/1.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Documentation (from link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GET /models` returns a list of the available models.\n",
    "\n",
    "`POST /predict/<model_name>` asks the specified model for a prediction, based on the data in the request body. Each model expects different inputs:\n",
    "\n",
    "* Semantic Role Labeling: `{\"sentence\": \"...\"}`\n",
    "* Bidaf (question answering): `{\"paragraph\": \"...\", \"question\": \"...\"}`\n",
    "* Snli: `{\"premise\": \"...\", \"hypothesis\": \"...\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': ['machine-comprehension',\n",
       "  'semantic-role-labeling',\n",
       "  'textual-entailment',\n",
       "  'coreference-resolution',\n",
       "  'named-entity-recognition']}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://localhost:8000\"\n",
    "requests.get(url + \"/models\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_api(method, payload):\n",
    "    headers = {'content-type': \"application/json\"}\n",
    "    url = \"http://localhost:8000\"\n",
    "    resp = requests.request(\"POST\", \n",
    "                            url + \"/predict/{method}\".format(method=method), \n",
    "                            data=json.dumps(payload), \n",
    "                            headers=headers)    \n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textual Entailment API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label_logits': [2.001786470413208, -2.3041346073150635, -0.35969048738479614],\n",
      " 'label_probs': [0.9027150273323059, 0.012176231481134892, 0.08510876446962357]}\n"
     ]
    }
   ],
   "source": [
    "payload = {\"premise\":\"Changes in the amount of CO2 threaten the delicate balance required to keep corals healthy. So if coral don't get the right amount, they could turn white\",\n",
    "           \"hypothesis\":\"Increases in carbon dioxide cause coral bleaching\"}\n",
    "\n",
    "pprint(call_api(\"textual-entailment\", payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Comprehension API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_span': [0, 6],\n",
      " 'best_span_str': 'The world’s temperatures are constantly changing',\n",
      " 'span_end_logits': [-8.260040283203125,\n",
      "                     -7.483365535736084,\n",
      "                     -6.194005012512207,\n",
      "                     0.31115949153900146,\n",
      "                     -7.251424312591553,\n",
      "                     -6.025007724761963,\n",
      "                     0.7867436408996582,\n",
      "                     -1.9502825736999512,\n",
      "                     -7.713595867156982,\n",
      "                     -11.265436172485352,\n",
      "                     -9.199939727783203,\n",
      "                     -8.536502838134766,\n",
      "                     -9.122642517089844,\n",
      "                     -7.163054943084717,\n",
      "                     -9.061155319213867,\n",
      "                     -12.157005310058594,\n",
      "                     -10.687776565551758,\n",
      "                     -12.400985717773438,\n",
      "                     -11.765970230102539,\n",
      "                     -8.368474960327148],\n",
      " 'span_end_probs': [6.968861271161586e-05,\n",
      "                    0.000151519023347646,\n",
      "                    0.0005500843399204314,\n",
      "                    0.3677785098552704,\n",
      "                    0.00019107239495497197,\n",
      "                    0.0006513642147183418,\n",
      "                    0.5917386412620544,\n",
      "                    0.038322564214468,\n",
      "                    0.00012035922554787248,\n",
      "                    3.450920530667645e-06,\n",
      "                    2.7225047233514488e-05,\n",
      "                    5.285616498440504e-05,\n",
      "                    2.9412938602035865e-05,\n",
      "                    0.00020872586173936725,\n",
      "                    3.127821400994435e-05,\n",
      "                    1.4149183016343159e-06,\n",
      "                    6.149068667582469e-06,\n",
      "                    1.1085927553722286e-06,\n",
      "                    2.0919715097988956e-06,\n",
      "                    6.25272368779406e-05],\n",
      " 'span_start_logits': [2.6973769664764404,\n",
      "                       1.2591073513031006,\n",
      "                       -0.9678809642791748,\n",
      "                       -0.8050899505615234,\n",
      "                       -7.105669021606445,\n",
      "                       -4.053529262542725,\n",
      "                       -6.2880706787109375,\n",
      "                       -8.031379699707031,\n",
      "                       -6.678640365600586,\n",
      "                       -9.674893379211426,\n",
      "                       -6.054444313049316,\n",
      "                       -8.822016716003418,\n",
      "                       -6.995537757873535,\n",
      "                       -7.610770225524902,\n",
      "                       -4.708525657653809,\n",
      "                       -6.917242050170898,\n",
      "                       -5.50294828414917,\n",
      "                       -5.9422149658203125,\n",
      "                       -4.159503936767578,\n",
      "                       -3.5319910049438477],\n",
      " 'span_start_probs': [0.7698633670806885,\n",
      "                      0.18271790444850922,\n",
      "                      0.01970663107931614,\n",
      "                      0.023190578445792198,\n",
      "                      4.2560306610539556e-05,\n",
      "                      0.0009006009786389768,\n",
      "                      9.640137432143092e-05,\n",
      "                      1.6864511053427123e-05,\n",
      "                      6.523203774122521e-05,\n",
      "                      3.259904133301461e-06,\n",
      "                      0.00012177155440440401,\n",
      "                      7.64899596106261e-06,\n",
      "                      4.751537926495075e-05,\n",
      "                      2.568278432590887e-05,\n",
      "                      0.00046781153650954366,\n",
      "                      5.138514097779989e-05,\n",
      "                      0.00021137700241524726,\n",
      "                      0.00013623430277220905,\n",
      "                      0.0008100428967736661,\n",
      "                      0.0015171670820564032]}\n"
     ]
    }
   ],
   "source": [
    "payload = {\"passage\":\"The world’s temperatures are constantly changing. This is one reason coral bleaching goes on the in the world\",\n",
    "           \"question\":\"What causes coral bleaching\"}\n",
    "\n",
    "pprint(call_api(\"machine-comprehension\", payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
